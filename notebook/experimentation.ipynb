{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup Success Prediction ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About Dataset**\n",
    "\n",
    "Context:\n",
    "A startup or start-up is a company or project begun by an entrepreneur to seek, develop, and validate a scalable economic model. While entrepreneurship refers to all new businesses, including self-employment and businesses that never intend to become registered, startups refer to new businesses that intend to grow large beyond the solo founder. \n",
    "\n",
    "Startups face high uncertainty and have high rates of failure, but a minority of them do go on to be successful and influential. \n",
    "\n",
    "Some startups become unicorns: privately held startup companies valued at over US$1 billion.\n",
    "\n",
    "**The objective**\n",
    "\n",
    "Predict whether a startup which is currently operating turns into a success or a failure. The success of a company is defined as the event that gives the company's founders a large sum of money through the process of M&A (Merger and Acquisition) or an IPO (Initial Public Offering). A company would be considered as failed if it had to be shut down.\n",
    "\n",
    "**About the Data**\n",
    "\n",
    "The data contains industry trends, investment insights and individual company information. There are 48 columns/features. Some of the features are:\n",
    "\n",
    "- age_first_funding_year – quantitative\n",
    "- age_last_funding_year – quantitative\n",
    "- relationships – quantitative\n",
    "- funding_rounds – quantitative\n",
    "- funding_total_usd – quantitative\n",
    "- milestones – quantitative\n",
    "- age_first_milestone_year – quantitative\n",
    "- age_last_milestone_year – quantitative\n",
    "- state – categorical\n",
    "- industry_type – categorical\n",
    "- has_VC – categorical\n",
    "- has_angel – categorical\n",
    "- has_roundA – categorical\n",
    "- has_roundB – categorical\n",
    "- has_roundC – categorical\n",
    "- has_roundD – categorical\n",
    "- avg_participants – quantitative\n",
    "- is_top500 – categorical\n",
    "- status(acquired/closed) – categorical (the target variable, if a startup is ‘acquired’ by some other organization, means the startup succeed) \n",
    "\n",
    "These variables are likely binary indicators (0 or 1) provide information about the startup's funding history, specifically whether it has received funding from angel investors and whether it has successfully completed funding rounds at different stages (A, B, C, D). They can be valuable features in predicting the success or failure of a startup, as funding rounds and investment from angels are often associated with the growth and potential success of a company.\n",
    "Notes: Each funding round represents a different stage of investment, and startups may not follow a strict sequential order (A, B, C, D). The order can vary based on the business's specific circumstances and the preferences of investors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import the necessary libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Loading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gabrielaarzate/Desktop/predicting_startup_succes/notebook\n"
     ]
    }
   ],
   "source": [
    "#Make sure you're aware of the current working directory in your Jupyter notebook.\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming this notebook is in the 'notebook' directory\n",
    "notebook_directory = '/Users/gabrielaarzate/Desktop/predicting_startup_succes/notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full file path from the notebook directory\n",
    "file_path = os.path.join(notebook_directory, '..', 'data', 'startup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to read in our training and testing data using pd.read_csv, \n",
    "#and take a first look using the describe() function.\n",
    "data = pd.read_csv(file_path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Explore the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 923 entries, 0 to 922\n",
      "Data columns (total 49 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                923 non-null    int64  \n",
      " 1   state_code                923 non-null    object \n",
      " 2   latitude                  923 non-null    float64\n",
      " 3   longitude                 923 non-null    float64\n",
      " 4   zip_code                  923 non-null    object \n",
      " 5   id                        923 non-null    object \n",
      " 6   city                      923 non-null    object \n",
      " 7   Unnamed: 6                430 non-null    object \n",
      " 8   name                      923 non-null    object \n",
      " 9   labels                    923 non-null    int64  \n",
      " 10  founded_at                923 non-null    object \n",
      " 11  closed_at                 335 non-null    object \n",
      " 12  first_funding_at          923 non-null    object \n",
      " 13  last_funding_at           923 non-null    object \n",
      " 14  age_first_funding_year    923 non-null    float64\n",
      " 15  age_last_funding_year     923 non-null    float64\n",
      " 16  age_first_milestone_year  771 non-null    float64\n",
      " 17  age_last_milestone_year   771 non-null    float64\n",
      " 18  relationships             923 non-null    int64  \n",
      " 19  funding_rounds            923 non-null    int64  \n",
      " 20  funding_total_usd         923 non-null    int64  \n",
      " 21  milestones                923 non-null    int64  \n",
      " 22  state_code.1              922 non-null    object \n",
      " 23  is_CA                     923 non-null    int64  \n",
      " 24  is_NY                     923 non-null    int64  \n",
      " 25  is_MA                     923 non-null    int64  \n",
      " 26  is_TX                     923 non-null    int64  \n",
      " 27  is_otherstate             923 non-null    int64  \n",
      " 28  category_code             923 non-null    object \n",
      " 29  is_software               923 non-null    int64  \n",
      " 30  is_web                    923 non-null    int64  \n",
      " 31  is_mobile                 923 non-null    int64  \n",
      " 32  is_enterprise             923 non-null    int64  \n",
      " 33  is_advertising            923 non-null    int64  \n",
      " 34  is_gamesvideo             923 non-null    int64  \n",
      " 35  is_ecommerce              923 non-null    int64  \n",
      " 36  is_biotech                923 non-null    int64  \n",
      " 37  is_consulting             923 non-null    int64  \n",
      " 38  is_othercategory          923 non-null    int64  \n",
      " 39  object_id                 923 non-null    object \n",
      " 40  has_VC                    923 non-null    int64  \n",
      " 41  has_angel                 923 non-null    int64  \n",
      " 42  has_roundA                923 non-null    int64  \n",
      " 43  has_roundB                923 non-null    int64  \n",
      " 44  has_roundC                923 non-null    int64  \n",
      " 45  has_roundD                923 non-null    int64  \n",
      " 46  avg_participants          923 non-null    float64\n",
      " 47  is_top500                 923 non-null    int64  \n",
      " 48  status                    923 non-null    object \n",
      "dtypes: float64(7), int64(28), object(14)\n",
      "memory usage: 353.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Variable ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "acquired    597\n",
       "closed      326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['status'].value_counts()\n",
    "#In a binary classification problem like predicting whether a startup \n",
    "#will be \"acquired\" or \"closed,\" a balanced dataset typically means that you have a roughly equal \n",
    "#number of examples for each class. In your case, you have 597 examples of \"acquired\" and 326 examples of \"closed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Analyse missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "state_code                    0\n",
       "latitude                      0\n",
       "longitude                     0\n",
       "zip_code                      0\n",
       "id                            0\n",
       "city                          0\n",
       "Unnamed: 6                  493\n",
       "name                          0\n",
       "labels                        0\n",
       "founded_at                    0\n",
       "closed_at                   588\n",
       "first_funding_at              0\n",
       "last_funding_at               0\n",
       "age_first_funding_year        0\n",
       "age_last_funding_year         0\n",
       "age_first_milestone_year    152\n",
       "age_last_milestone_year     152\n",
       "relationships                 0\n",
       "funding_rounds                0\n",
       "funding_total_usd             0\n",
       "milestones                    0\n",
       "state_code.1                  1\n",
       "is_CA                         0\n",
       "is_NY                         0\n",
       "is_MA                         0\n",
       "is_TX                         0\n",
       "is_otherstate                 0\n",
       "category_code                 0\n",
       "is_software                   0\n",
       "is_web                        0\n",
       "is_mobile                     0\n",
       "is_enterprise                 0\n",
       "is_advertising                0\n",
       "is_gamesvideo                 0\n",
       "is_ecommerce                  0\n",
       "is_biotech                    0\n",
       "is_consulting                 0\n",
       "is_othercategory              0\n",
       "object_id                     0\n",
       "has_VC                        0\n",
       "has_angel                     0\n",
       "has_roundA                    0\n",
       "has_roundB                    0\n",
       "has_roundC                    0\n",
       "has_roundD                    0\n",
       "avg_participants              0\n",
       "is_top500                     0\n",
       "status                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "null = pd.DataFrame(data.isnull().sum(), columns=[\"Null Values\"])\n",
    "null[\"% Missing Values\"] = (data.isna().sum() / len(data) * 100)\n",
    "null = null[null[\"% Missing Values\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_null = (\n",
    "    null.style\n",
    "    .background_gradient(cmap='viridis', low=0.2, high=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fb5b4_row0_col0, #T_fb5b4_row0_col1 {\n",
       "  background-color: #7ad151;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fb5b4_row1_col0, #T_fb5b4_row1_col1 {\n",
       "  background-color: #cde11d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fb5b4_row2_col0, #T_fb5b4_row2_col1, #T_fb5b4_row3_col0, #T_fb5b4_row3_col1 {\n",
       "  background-color: #2e6d8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fb5b4_row4_col0, #T_fb5b4_row4_col1 {\n",
       "  background-color: #453581;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fb5b4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fb5b4_level0_col0\" class=\"col_heading level0 col0\" >Null Values</th>\n",
       "      <th id=\"T_fb5b4_level0_col1\" class=\"col_heading level0 col1\" >% Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fb5b4_level0_row0\" class=\"row_heading level0 row0\" >Unnamed: 6</th>\n",
       "      <td id=\"T_fb5b4_row0_col0\" class=\"data row0 col0\" >493</td>\n",
       "      <td id=\"T_fb5b4_row0_col1\" class=\"data row0 col1\" >53.412784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb5b4_level0_row1\" class=\"row_heading level0 row1\" >closed_at</th>\n",
       "      <td id=\"T_fb5b4_row1_col0\" class=\"data row1 col0\" >588</td>\n",
       "      <td id=\"T_fb5b4_row1_col1\" class=\"data row1 col1\" >63.705309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb5b4_level0_row2\" class=\"row_heading level0 row2\" >age_first_milestone_year</th>\n",
       "      <td id=\"T_fb5b4_row2_col0\" class=\"data row2 col0\" >152</td>\n",
       "      <td id=\"T_fb5b4_row2_col1\" class=\"data row2 col1\" >16.468039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb5b4_level0_row3\" class=\"row_heading level0 row3\" >age_last_milestone_year</th>\n",
       "      <td id=\"T_fb5b4_row3_col0\" class=\"data row3 col0\" >152</td>\n",
       "      <td id=\"T_fb5b4_row3_col1\" class=\"data row3 col1\" >16.468039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb5b4_level0_row4\" class=\"row_heading level0 row4\" >state_code.1</th>\n",
       "      <td id=\"T_fb5b4_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_fb5b4_row4_col1\" class=\"data row4 col1\" >0.108342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13dac36e0>"
      ]
     },
     "execution_count": 1751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_null\n",
    "#We have 5 columns with missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Irrelevant features: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Unnamed_0**: Appears to be an artifact of the data and often serves as an index or a row identifier.\n",
    "- **id**: irrelevant \n",
    "- **Unnamed_6** : Repeating values from others columns(city, state_code,zip_code).\n",
    "- **closed_at** : Irrelevant for now\n",
    "- **state_code.1** : Has the same information as state.code column \n",
    "- **object_id** : Same information as id.\n",
    "- **is_CA,is_NY,is_MA,is_TX,is_otherstate**: same information as state code.\n",
    "- **is_software,is_web,is_mobile, is_enterprise, is_advertising, is_gamesvideo, is_ecommerce, is_biotech, is_consulting, is_othercategory** : same information as category_code.\n",
    "\n",
    "We will drop 21 features that are irrelevant or repeating information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 . Data Cleaning ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 1 Drop the irrelevant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>founded_at</th>\n",
       "      <th>first_funding_at</th>\n",
       "      <th>last_funding_at</th>\n",
       "      <th>...</th>\n",
       "      <th>category_code</th>\n",
       "      <th>has_VC</th>\n",
       "      <th>has_angel</th>\n",
       "      <th>has_roundA</th>\n",
       "      <th>has_roundB</th>\n",
       "      <th>has_roundC</th>\n",
       "      <th>has_roundD</th>\n",
       "      <th>avg_participants</th>\n",
       "      <th>is_top500</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>42.358880</td>\n",
       "      <td>-71.056820</td>\n",
       "      <td>92101</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Bandsintown</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2007</td>\n",
       "      <td>4/1/2009</td>\n",
       "      <td>1/1/2010</td>\n",
       "      <td>...</td>\n",
       "      <td>music</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.238916</td>\n",
       "      <td>-121.973718</td>\n",
       "      <td>95032</td>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>TriCipher</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2000</td>\n",
       "      <td>2/14/2005</td>\n",
       "      <td>12/28/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>32.901049</td>\n",
       "      <td>-117.192656</td>\n",
       "      <td>92121</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Plixi</td>\n",
       "      <td>1</td>\n",
       "      <td>3/18/2009</td>\n",
       "      <td>3/30/2010</td>\n",
       "      <td>3/30/2010</td>\n",
       "      <td>...</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.320309</td>\n",
       "      <td>-122.050040</td>\n",
       "      <td>95014</td>\n",
       "      <td>Cupertino</td>\n",
       "      <td>Solidcore Systems</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2002</td>\n",
       "      <td>2/17/2005</td>\n",
       "      <td>4/25/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>software</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.779281</td>\n",
       "      <td>-122.419236</td>\n",
       "      <td>94105</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Inhale Digital</td>\n",
       "      <td>0</td>\n",
       "      <td>8/1/2010</td>\n",
       "      <td>8/1/2010</td>\n",
       "      <td>4/1/2012</td>\n",
       "      <td>...</td>\n",
       "      <td>games_video</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.740594</td>\n",
       "      <td>-122.376471</td>\n",
       "      <td>94107</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CoTweet</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2009</td>\n",
       "      <td>7/9/2009</td>\n",
       "      <td>7/9/2009</td>\n",
       "      <td>...</td>\n",
       "      <td>advertising</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>MA</td>\n",
       "      <td>42.504817</td>\n",
       "      <td>-71.195611</td>\n",
       "      <td>1803</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>Reef Point Systems</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1998</td>\n",
       "      <td>4/1/2005</td>\n",
       "      <td>3/23/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>security</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.408261</td>\n",
       "      <td>-122.015920</td>\n",
       "      <td>94089</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Paracor Medical</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1999</td>\n",
       "      <td>6/29/2007</td>\n",
       "      <td>6/29/2007</td>\n",
       "      <td>...</td>\n",
       "      <td>biotech</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.556732</td>\n",
       "      <td>-122.288378</td>\n",
       "      <td>94404</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Causata</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2009</td>\n",
       "      <td>10/5/2009</td>\n",
       "      <td>11/1/2011</td>\n",
       "      <td>...</td>\n",
       "      <td>software</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>CA</td>\n",
       "      <td>37.386778</td>\n",
       "      <td>-121.966277</td>\n",
       "      <td>95054</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Asempra Technologies</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2003</td>\n",
       "      <td>2/13/2006</td>\n",
       "      <td>2/13/2006</td>\n",
       "      <td>...</td>\n",
       "      <td>security</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_code   latitude   longitude zip_code           city  \\\n",
       "0           CA  42.358880  -71.056820    92101      San Diego   \n",
       "1           CA  37.238916 -121.973718    95032      Los Gatos   \n",
       "2           CA  32.901049 -117.192656    92121      San Diego   \n",
       "3           CA  37.320309 -122.050040    95014      Cupertino   \n",
       "4           CA  37.779281 -122.419236    94105  San Francisco   \n",
       "..         ...        ...         ...      ...            ...   \n",
       "918         CA  37.740594 -122.376471    94107  San Francisco   \n",
       "919         MA  42.504817  -71.195611     1803     Burlington   \n",
       "920         CA  37.408261 -122.015920    94089      Sunnyvale   \n",
       "921         CA  37.556732 -122.288378    94404  San Francisco   \n",
       "922         CA  37.386778 -121.966277    95054    Santa Clara   \n",
       "\n",
       "                     name  labels founded_at first_funding_at last_funding_at  \\\n",
       "0             Bandsintown       1   1/1/2007         4/1/2009        1/1/2010   \n",
       "1               TriCipher       1   1/1/2000        2/14/2005      12/28/2009   \n",
       "2                   Plixi       1  3/18/2009        3/30/2010       3/30/2010   \n",
       "3       Solidcore Systems       1   1/1/2002        2/17/2005       4/25/2007   \n",
       "4          Inhale Digital       0   8/1/2010         8/1/2010        4/1/2012   \n",
       "..                    ...     ...        ...              ...             ...   \n",
       "918               CoTweet       1   1/1/2009         7/9/2009        7/9/2009   \n",
       "919    Reef Point Systems       0   1/1/1998         4/1/2005       3/23/2007   \n",
       "920       Paracor Medical       0   1/1/1999        6/29/2007       6/29/2007   \n",
       "921               Causata       1   1/1/2009        10/5/2009       11/1/2011   \n",
       "922  Asempra Technologies       1   1/1/2003        2/13/2006       2/13/2006   \n",
       "\n",
       "     ...  category_code  has_VC  has_angel  has_roundA  has_roundB  \\\n",
       "0    ...          music       0          1           0           0   \n",
       "1    ...     enterprise       1          0           0           1   \n",
       "2    ...            web       0          0           1           0   \n",
       "3    ...       software       0          0           0           1   \n",
       "4    ...    games_video       1          1           0           0   \n",
       "..   ...            ...     ...        ...         ...         ...   \n",
       "918  ...    advertising       0          0           1           0   \n",
       "919  ...       security       1          0           0           1   \n",
       "920  ...        biotech       0          0           0           0   \n",
       "921  ...       software       0          0           1           1   \n",
       "922  ...       security       0          0           0           1   \n",
       "\n",
       "     has_roundC  has_roundD  avg_participants is_top500    status  \n",
       "0             0           0            1.0000         0  acquired  \n",
       "1             1           1            4.7500         1  acquired  \n",
       "2             0           0            4.0000         1  acquired  \n",
       "3             1           1            3.3333         1  acquired  \n",
       "4             0           0            1.0000         1    closed  \n",
       "..          ...         ...               ...       ...       ...  \n",
       "918           0           0            6.0000         1  acquired  \n",
       "919           0           0            2.6667         1    closed  \n",
       "920           0           1            8.0000         1    closed  \n",
       "921           0           0            1.0000         1  acquired  \n",
       "922           0           0            3.0000         1  acquired  \n",
       "\n",
       "[923 rows x 28 columns]"
      ]
     },
     "execution_count": 1752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 0', 'id', 'Unnamed: 6', 'closed_at', 'state_code.1', 'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory', 'object_id'], axis=1).copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping irrelevant features The DataFrame has 28 columns.\n"
     ]
    }
   ],
   "source": [
    "num_columns = len(data.columns)\n",
    "print(f\"After dropping irrelevant features The DataFrame has {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 2 Handle Missing Values of 2 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we had 5 columns with missing values, 3 of them were irrelevant(Unnamed: 6, state_code.1, closed_at) so \n",
    "#we dropped them now we need to input data to only 2 differents variables.\n",
    "\n",
    "# 1. age_first_milestone_year\n",
    "# 2. age_last_milestone_year \n",
    "\n",
    "# 2. Impute missing values with 0 to 'age_first_milestone_year'\n",
    "data['age_first_milestone_year'].fillna(0, inplace=True)\n",
    "\n",
    "# 3. Impute missing values with 0 to 'age_last_milestone_year'\n",
    "data['age_last_milestone_year'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_code                  0\n",
       "latitude                    0\n",
       "longitude                   0\n",
       "zip_code                    0\n",
       "city                        0\n",
       "name                        0\n",
       "labels                      0\n",
       "founded_at                  0\n",
       "first_funding_at            0\n",
       "last_funding_at             0\n",
       "age_first_funding_year      0\n",
       "age_last_funding_year       0\n",
       "age_first_milestone_year    0\n",
       "age_last_milestone_year     0\n",
       "relationships               0\n",
       "funding_rounds              0\n",
       "funding_total_usd           0\n",
       "milestones                  0\n",
       "category_code               0\n",
       "has_VC                      0\n",
       "has_angel                   0\n",
       "has_roundA                  0\n",
       "has_roundB                  0\n",
       "has_roundC                  0\n",
       "has_roundD                  0\n",
       "avg_participants            0\n",
       "is_top500                   0\n",
       "status                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_code                   object\n",
      "latitude                    float64\n",
      "longitude                   float64\n",
      "zip_code                     object\n",
      "city                         object\n",
      "name                         object\n",
      "labels                        int64\n",
      "founded_at                   object\n",
      "first_funding_at             object\n",
      "last_funding_at              object\n",
      "age_first_funding_year      float64\n",
      "age_last_funding_year       float64\n",
      "age_first_milestone_year    float64\n",
      "age_last_milestone_year     float64\n",
      "relationships                 int64\n",
      "funding_rounds                int64\n",
      "funding_total_usd             int64\n",
      "milestones                    int64\n",
      "category_code                object\n",
      "has_VC                        int64\n",
      "has_angel                     int64\n",
      "has_roundA                    int64\n",
      "has_roundB                    int64\n",
      "has_roundC                    int64\n",
      "has_roundD                    int64\n",
      "avg_participants            float64\n",
      "is_top500                     int64\n",
      "status                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Analyzing Categorical Data to convert to Numerical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features (19):\n",
      "['latitude', 'longitude', 'labels', 'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year', 'age_last_milestone_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones', 'has_VC', 'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants', 'is_top500']\n",
      "\n",
      "Categorical Features (9):\n",
      "['state_code', 'zip_code', 'city', 'name', 'founded_at', 'first_funding_at', 'last_funding_at', 'category_code', 'status']\n",
      "\n",
      "Target Variable (1):\n",
      "['status']\n"
     ]
    }
   ],
   "source": [
    "numerical_features = data.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Assuming the target variable is 'status'\n",
    "target_variable = ['status']\n",
    "\n",
    "# Print the lists along with the number of features\n",
    "print(\"Numerical Features ({0}):\".format(len(numerical_features)))\n",
    "print(numerical_features)\n",
    "\n",
    "print(\"\\nCategorical Features ({0}):\".format(len(categorical_features)))\n",
    "print(categorical_features)\n",
    "\n",
    "print(\"\\nTarget Variable ({0}):\".format(len(target_variable)))\n",
    "print(target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: state_code\n",
      "Unique Values (Subset):\n",
      "['CA' 'MA' 'KY' 'NY' 'CO' 'VA' 'TX' 'WA' 'IL' 'NC']\n",
      "\n",
      "Column: zip_code\n",
      "Unique Values (Subset):\n",
      "['92101' '95032' '92121' '95014' '94105' '94043' '94041' '94901' '1267'\n",
      " '94306']\n",
      "\n",
      "Column: city\n",
      "Unique Values (Subset):\n",
      "['San Diego' 'Los Gatos' 'Cupertino' 'San Francisco' 'Mountain View'\n",
      " 'San Rafael' 'Williamstown' 'Palo Alto' 'Menlo Park' 'Louisville']\n",
      "\n",
      "Column: name\n",
      "Unique Values (Subset):\n",
      "['Bandsintown' 'TriCipher' 'Plixi' 'Solidcore Systems' 'Inhale Digital'\n",
      " 'Matisse Networks' 'RingCube Technologies' 'ClairMail' 'VoodooVox'\n",
      " 'Doostang']\n",
      "\n",
      "Column: founded_at\n",
      "Unique Values (Subset):\n",
      "['1/1/2007' '1/1/2000' '3/18/2009' '1/1/2002' '8/1/2010' '1/1/2005'\n",
      " '1/1/2004' '6/1/2005' '11/15/2000' '1/1/2006']\n",
      "\n",
      "Column: first_funding_at\n",
      "Unique Values (Subset):\n",
      "['4/1/2009' '2/14/2005' '3/30/2010' '2/17/2005' '8/1/2010' '7/18/2006'\n",
      " '9/21/2006' '8/24/2005' '8/2/2005' '2/1/2007']\n",
      "\n",
      "Column: last_funding_at\n",
      "Unique Values (Subset):\n",
      "['1/1/2010' '12/28/2009' '3/30/2010' '4/25/2007' '4/1/2012' '7/18/2006'\n",
      " '3/18/2010' '10/4/2010' '2/8/2013' '2/5/2010']\n",
      "\n",
      "Column: category_code\n",
      "Unique Values (Subset):\n",
      "['music' 'enterprise' 'web' 'software' 'games_video' 'network_hosting'\n",
      " 'finance' 'mobile' 'education' 'public_relations']\n",
      "\n",
      "Column: status\n",
      "Unique Values (Subset):\n",
      "['acquired' 'closed']\n"
     ]
    }
   ],
   "source": [
    "#1. Categorical Data ir Nominal or Ordinal?\n",
    "\n",
    "# Assuming your_data_df is your main DataFrame\n",
    "your_data_df = data\n",
    "\n",
    "# List of your categorical columns\n",
    "categorical_columns =  your_data_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Loop through each categorical column and display a subset of unique values\n",
    "for categorical_column in categorical_columns:\n",
    "    unique_values = your_data_df[categorical_column].unique()\n",
    "    \n",
    "    print(f\"\\nColumn: {categorical_column}\")\n",
    "    print(\"Unique Values (Subset):\")\n",
    "    print(unique_values[:10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Converting Datetime to Numerical int64\n",
    "\n",
    "- these variables : 'founded_at', 'first_funding_at', 'last_funding_at'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_code                   object\n",
      "latitude                    float64\n",
      "longitude                   float64\n",
      "zip_code                     object\n",
      "city                         object\n",
      "name                         object\n",
      "labels                        int64\n",
      "founded_at                    int64\n",
      "first_funding_at              int64\n",
      "last_funding_at               int64\n",
      "age_first_funding_year      float64\n",
      "age_last_funding_year       float64\n",
      "age_first_milestone_year    float64\n",
      "age_last_milestone_year     float64\n",
      "relationships                 int64\n",
      "funding_rounds                int64\n",
      "funding_total_usd             int64\n",
      "milestones                    int64\n",
      "category_code                object\n",
      "has_VC                        int64\n",
      "has_angel                     int64\n",
      "has_roundA                    int64\n",
      "has_roundB                    int64\n",
      "has_roundC                    int64\n",
      "has_roundD                    int64\n",
      "avg_participants            float64\n",
      "is_top500                     int64\n",
      "status                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your_data_df is your main DataFrame\n",
    "your_data_df = data\n",
    "\n",
    "# List of date columns\n",
    "date_columns = ['founded_at', 'first_funding_at', 'last_funding_at']\n",
    "\n",
    "# Convert date columns to datetime\n",
    "for date_column in date_columns:\n",
    "    your_data_df[date_column] = pd.to_datetime(your_data_df[date_column], errors='coerce')\n",
    "\n",
    "# Convert datetime to timestamp (numerical)\n",
    "for date_column in date_columns:\n",
    "    your_data_df[date_column] = your_data_df[date_column].astype(int)\n",
    "\n",
    "# Display the result\n",
    "print(your_data_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now variables in numerical columns not in categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: latitude\n",
      "Unique Values (Subset):\n",
      "[42.35888   37.238916  32.901049  37.320309  37.779281  37.406914\n",
      " 37.3915589 38.057107  42.712207  37.427235 ]\n",
      "\n",
      "Column: longitude\n",
      "Unique Values (Subset):\n",
      "[ -71.05682   -121.973718  -117.192656  -122.05004   -122.419236\n",
      " -122.09037   -122.0702643 -122.513742   -73.203599  -122.145783 ]\n",
      "\n",
      "Column: labels\n",
      "Unique Values (Subset):\n",
      "[1 0]\n",
      "\n",
      "Column: founded_at\n",
      "Unique Values (Subset):\n",
      "[1167609600000000000  946684800000000000 1237334400000000000\n",
      " 1009843200000000000 1280620800000000000 1104537600000000000\n",
      " 1072915200000000000 1117584000000000000  974246400000000000\n",
      " 1136073600000000000]\n",
      "\n",
      "Column: first_funding_at\n",
      "Unique Values (Subset):\n",
      "[1238544000000000000 1108339200000000000 1269907200000000000\n",
      " 1108598400000000000 1280620800000000000 1153180800000000000\n",
      " 1158796800000000000 1124841600000000000 1122940800000000000\n",
      " 1170288000000000000]\n",
      "\n",
      "Column: last_funding_at\n",
      "Unique Values (Subset):\n",
      "[1262304000000000000 1261958400000000000 1269907200000000000\n",
      " 1177459200000000000 1333238400000000000 1153180800000000000\n",
      " 1268870400000000000 1286150400000000000 1360281600000000000\n",
      " 1265328000000000000]\n",
      "\n",
      "Column: age_first_funding_year\n",
      "Unique Values (Subset):\n",
      "[2.2493 5.126  1.0329 3.1315 0.     4.5452 1.7205 1.6466 3.5863 1.6712]\n",
      "\n",
      "Column: age_last_funding_year\n",
      "Unique Values (Subset):\n",
      "[ 3.0027  9.9973  1.0329  5.3151  1.6685  4.5452  5.211   6.7616 11.1123\n",
      "  4.6849]\n",
      "\n",
      "Column: age_first_milestone_year\n",
      "Unique Values (Subset):\n",
      "[4.6685 7.0055 1.4575 6.0027 0.0384 5.0027 3.     5.6055 8.0055 2.9178]\n",
      "\n",
      "Column: age_last_milestone_year\n",
      "Unique Values (Subset):\n",
      "[6.7041 7.0055 2.2055 6.0027 0.0384 5.0027 6.6082 7.3616 9.9945 6.1151]\n",
      "\n",
      "Column: relationships\n",
      "Unique Values (Subset):\n",
      "[ 3  9  5  2  6 25 13 14 22  8]\n",
      "\n",
      "Column: funding_rounds\n",
      "Unique Values (Subset):\n",
      "[ 3  4  1  2  5  7  6 10  8]\n",
      "\n",
      "Column: funding_total_usd\n",
      "Unique Values (Subset):\n",
      "[  375000 40100000  2600000 40000000  1300000  7500000 26000000 34100000\n",
      "  9650000  5750000]\n",
      "\n",
      "Column: milestones\n",
      "Unique Values (Subset):\n",
      "[3 1 2 4 0 5 6 8]\n",
      "\n",
      "Column: has_VC\n",
      "Unique Values (Subset):\n",
      "[0 1]\n",
      "\n",
      "Column: has_angel\n",
      "Unique Values (Subset):\n",
      "[1 0]\n",
      "\n",
      "Column: has_roundA\n",
      "Unique Values (Subset):\n",
      "[0 1]\n",
      "\n",
      "Column: has_roundB\n",
      "Unique Values (Subset):\n",
      "[0 1]\n",
      "\n",
      "Column: has_roundC\n",
      "Unique Values (Subset):\n",
      "[0 1]\n",
      "\n",
      "Column: has_roundD\n",
      "Unique Values (Subset):\n",
      "[0 1]\n",
      "\n",
      "Column: avg_participants\n",
      "Unique Values (Subset):\n",
      "[1.     4.75   4.     3.3333 3.     1.6667 3.5    1.75   2.3333 2.5   ]\n",
      "\n",
      "Column: is_top500\n",
      "Unique Values (Subset):\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming your_data_df is your main DataFrame\n",
    "your_data_df = data\n",
    "\n",
    "# List of your categorical columns\n",
    "numerical_columns = your_data_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Loop through each categorical column and display a subset of unique values\n",
    "for numerical_columns in numerical_columns:\n",
    "    unique_values = your_data_df[numerical_columns].unique()\n",
    "    \n",
    "    print(f\"\\nColumn: {numerical_columns}\")\n",
    "    print(\"Unique Values (Subset):\")\n",
    "    print(unique_values[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: state_code\n",
      "Unique Values (Subset):\n",
      "['CA' 'MA' 'KY' 'NY' 'CO' 'VA' 'TX' 'WA' 'IL' 'NC' 'PA' 'GA' 'NH' 'MO'\n",
      " 'FL' 'NJ' 'WV' 'MI' 'DC' 'CT' 'MD' 'OH' 'TN' 'MN' 'RI' 'OR' 'UT' 'ME'\n",
      " 'NV' 'NM' 'IN' 'AZ' 'ID' 'AR' 'WI']\n",
      "\n",
      "Column: zip_code\n",
      "Unique Values (Subset):\n",
      "['92101' '95032' '92121' '95014' '94105' '94043' '94041' '94901' '1267'\n",
      " '94306' '94025' '40204' '11201' '80202' '22182' '94022' '94010' '10004'\n",
      " '94301' '78735' '98122' '94103' '80302' '60601' '94303' '94704' '78701'\n",
      " '92705' '94035' '98119' '27701' '15219' '10011' '94111' '95134' '94107'\n",
      " '10010' '30303' '3101' '98102' '94089' '94085' '100011' '2139' '94607'\n",
      " '94404' '94080' '2210' '78731' '2451' '95128' '92656' '64106' '1887'\n",
      " '98033-6314' '33609' '02111-1720' '94501' '98011' '94403-1855' '94104'\n",
      " '94087' '33626' '75001' '94538' '95051' '2138' '8540' '80538' '10012'\n",
      " '25430' '90025' '48187' '98004' '95054' '20007' '94110' '10173' '60606'\n",
      " '8873' '94710' '30009' '98104' '22902' '20166' '60607' '6002' '60401'\n",
      " '95035-6261' '27606' '10001' '2143' '94065' '10003' '21093' '15213'\n",
      " '20191' '10019' '45202' '30305']\n",
      "\n",
      "Column: city\n",
      "Unique Values (Subset):\n",
      "['San Diego' 'Los Gatos' 'Cupertino' 'San Francisco' 'Mountain View'\n",
      " 'San Rafael' 'Williamstown' 'Palo Alto' 'Menlo Park' 'Louisville'\n",
      " 'Brooklyn' 'Denver' 'Vienna' 'Los Altos' 'Burlingame' 'New York' 'Austin'\n",
      " 'Seattle' 'Boulder' 'Chicago' 'Berkeley' 'Santa Ana' 'Moffett Field'\n",
      " 'Durham' 'Pittsburgh' 'San Jose' 'Atlanta' 'Manchester' 'Sunnyvale'\n",
      " 'Cambridge' 'San Mateo' 'South San Francisco' 'Boston' 'Waltham'\n",
      " 'Aliso Viejo' 'Kansas City' 'Wilmington' 'Kirkland' 'Tampa' 'Alameda'\n",
      " 'Bothell' 'Dallas' 'Fremont' 'Santa Clara' 'Princeton' 'Loveland'\n",
      " 'Kearneysville' 'Los Angeles' 'Canton' 'Bellevue' 'Washington' 'Somerset'\n",
      " 'Alpharetta' 'Charlottesville' 'Dulles' 'Bloomfield' 'Santa Monica'\n",
      " 'Milpitas' 'Raleigh' 'Somerville' 'Redwood City' 'Timonium' 'Reston'\n",
      " 'Cincinnati' 'Campbell' 'Sterling' 'Foster City' 'Oakland' 'Petaluma'\n",
      " 'Arlington' 'Centennial' 'Memphis' 'Plymouth' 'Conshohocken' 'Needham'\n",
      " 'Newport Beach' 'Longmont' 'Naperville' 'Pasadena' 'Warrenville' 'Berwyn'\n",
      " 'Morgan Hill' 'Marlborough' 'Playa Vista' 'Providence' 'Monterey Park'\n",
      " 'Plano' 'Bingham Farms' 'Philadelphia' 'Freedom' 'Bethesda' 'Portland'\n",
      " 'Allentown' 'North Billerica' 'Duluth' 'Boxborough' 'Salt Lake City'\n",
      " 'The Woodlands' 'Burlington' 'Weston']\n",
      "\n",
      "Column: name\n",
      "Unique Values (Subset):\n",
      "['Bandsintown' 'TriCipher' 'Plixi' 'Solidcore Systems' 'Inhale Digital'\n",
      " 'Matisse Networks' 'RingCube Technologies' 'ClairMail' 'VoodooVox'\n",
      " 'Doostang' 'Zong' \"Center'd\" 'Resonant Vibes' 'drop.io' 'Stratavia'\n",
      " 'Invicta Networks' 'QSecure' 'MeeVee' 'SinglePlatform' 'Bling Nation'\n",
      " 'Metreos Corporation' 'Hidden City Games' 'Neopolitan Networks'\n",
      " 'Pixelpipe' 'EventVue' 'BridgePort Networks' 'Scalent Systems'\n",
      " 'IQ Engines' 'RetailMeNot, Inc.' 'Mophie' 'Airship Ventures'\n",
      " 'Lockdown Networks' 'eMinor' 'Karma' 'Zipano' 'Entertainment Media Works'\n",
      " 'Elastra' 'RPO' 'Fotomoto' 'Peer39' 'Vitrue' 'Trendslide' 'PublicEarth'\n",
      " 'Azaleos' 'Efficient Frontier' 'NetDevices' 'Go Try It On' 'Performable'\n",
      " 'Appstores.com' 'Fortify Software' 'iCurrent' 'AisleBuyer' 'Indeed'\n",
      " 'Colubris Networks' 'Mashery' 'Transparency Software' 'Viewdle'\n",
      " 'Enclarity' 'Virsto Software' 'Handmark' 'Viacor' 'Carbonetworks'\n",
      " 'SchemaLogic' 'Skyway Software' 'CardStar' 'Makani Power' 'Myrio'\n",
      " 'Intela' 'Sana Security' 'Sportgenic' 'Lolapps' 'Behavio' 'Infinity Box'\n",
      " 'adBrite' 'Texert' 'Mendocino Software' 'QuikCycle' 'Instagram'\n",
      " 'Motionbox' 'AccelGolf' 'MoPub' 'DNP Green Technology' 'Abound Solar'\n",
      " 'Trovix' 'Thumbplay' 'Plethora Technology' 'DailyStrength'\n",
      " 'Danotek Motion Technologies' 'Yub' 'SNAPin Software' 'Azuro' 'ARPU'\n",
      " 'BookFresh' 'Singly' 'TxVia' 'Blue Vector Systems' 'Open Kernel Labs'\n",
      " 'Elanti Systems' 'Astrid' 'Nordic Windpower']\n",
      "\n",
      "Column: category_code\n",
      "Unique Values (Subset):\n",
      "['music' 'enterprise' 'web' 'software' 'games_video' 'network_hosting'\n",
      " 'finance' 'mobile' 'education' 'public_relations' 'security' 'other'\n",
      " 'photo_video' 'hardware' 'ecommerce' 'advertising' 'travel' 'fashion'\n",
      " 'analytics' 'consulting' 'biotech' 'cleantech' 'search' 'semiconductor'\n",
      " 'social' 'medical' 'automotive' 'messaging' 'manufacturing' 'hospitality'\n",
      " 'news' 'transportation' 'sports' 'real_estate' 'health']\n",
      "\n",
      "Column: status\n",
      "Unique Values (Subset):\n",
      "['acquired' 'closed']\n"
     ]
    }
   ],
   "source": [
    "# Assuming your_data_df is your main DataFrame\n",
    "your_data_df = data\n",
    "\n",
    "# List of your categorical columns\n",
    "categorical_columns =  your_data_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Loop through each categorical column and display a subset of unique values\n",
    "for categorical_column in categorical_columns:\n",
    "    unique_values = your_data_df[categorical_column].unique()\n",
    "    \n",
    "    print(f\"\\nColumn: {categorical_column}\")\n",
    "    print(\"Unique Values (Subset):\")\n",
    "    print(unique_values[:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Dummies for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1762,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = pd.get_dummies(data, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>labels</th>\n",
       "      <th>founded_at</th>\n",
       "      <th>first_funding_at</th>\n",
       "      <th>last_funding_at</th>\n",
       "      <th>age_first_funding_year</th>\n",
       "      <th>age_last_funding_year</th>\n",
       "      <th>age_first_milestone_year</th>\n",
       "      <th>age_last_milestone_year</th>\n",
       "      <th>...</th>\n",
       "      <th>category_code_security</th>\n",
       "      <th>category_code_semiconductor</th>\n",
       "      <th>category_code_social</th>\n",
       "      <th>category_code_software</th>\n",
       "      <th>category_code_sports</th>\n",
       "      <th>category_code_transportation</th>\n",
       "      <th>category_code_travel</th>\n",
       "      <th>category_code_web</th>\n",
       "      <th>status_acquired</th>\n",
       "      <th>status_closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.358880</td>\n",
       "      <td>-71.056820</td>\n",
       "      <td>1</td>\n",
       "      <td>1167609600000000000</td>\n",
       "      <td>1238544000000000000</td>\n",
       "      <td>1262304000000000000</td>\n",
       "      <td>2.2493</td>\n",
       "      <td>3.0027</td>\n",
       "      <td>4.6685</td>\n",
       "      <td>6.7041</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.238916</td>\n",
       "      <td>-121.973718</td>\n",
       "      <td>1</td>\n",
       "      <td>946684800000000000</td>\n",
       "      <td>1108339200000000000</td>\n",
       "      <td>1261958400000000000</td>\n",
       "      <td>5.1260</td>\n",
       "      <td>9.9973</td>\n",
       "      <td>7.0055</td>\n",
       "      <td>7.0055</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.901049</td>\n",
       "      <td>-117.192656</td>\n",
       "      <td>1</td>\n",
       "      <td>1237334400000000000</td>\n",
       "      <td>1269907200000000000</td>\n",
       "      <td>1269907200000000000</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>1.4575</td>\n",
       "      <td>2.2055</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.320309</td>\n",
       "      <td>-122.050040</td>\n",
       "      <td>1</td>\n",
       "      <td>1009843200000000000</td>\n",
       "      <td>1108598400000000000</td>\n",
       "      <td>1177459200000000000</td>\n",
       "      <td>3.1315</td>\n",
       "      <td>5.3151</td>\n",
       "      <td>6.0027</td>\n",
       "      <td>6.0027</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.779281</td>\n",
       "      <td>-122.419236</td>\n",
       "      <td>0</td>\n",
       "      <td>1280620800000000000</td>\n",
       "      <td>1280620800000000000</td>\n",
       "      <td>1333238400000000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6685</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1619 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  labels           founded_at     first_funding_at  \\\n",
       "0  42.358880  -71.056820       1  1167609600000000000  1238544000000000000   \n",
       "1  37.238916 -121.973718       1   946684800000000000  1108339200000000000   \n",
       "2  32.901049 -117.192656       1  1237334400000000000  1269907200000000000   \n",
       "3  37.320309 -122.050040       1  1009843200000000000  1108598400000000000   \n",
       "4  37.779281 -122.419236       0  1280620800000000000  1280620800000000000   \n",
       "\n",
       "       last_funding_at  age_first_funding_year  age_last_funding_year  \\\n",
       "0  1262304000000000000                  2.2493                 3.0027   \n",
       "1  1261958400000000000                  5.1260                 9.9973   \n",
       "2  1269907200000000000                  1.0329                 1.0329   \n",
       "3  1177459200000000000                  3.1315                 5.3151   \n",
       "4  1333238400000000000                  0.0000                 1.6685   \n",
       "\n",
       "   age_first_milestone_year  age_last_milestone_year  ...  \\\n",
       "0                    4.6685                   6.7041  ...   \n",
       "1                    7.0055                   7.0055  ...   \n",
       "2                    1.4575                   2.2055  ...   \n",
       "3                    6.0027                   6.0027  ...   \n",
       "4                    0.0384                   0.0384  ...   \n",
       "\n",
       "   category_code_security  category_code_semiconductor  category_code_social  \\\n",
       "0                   False                        False                 False   \n",
       "1                   False                        False                 False   \n",
       "2                   False                        False                 False   \n",
       "3                   False                        False                 False   \n",
       "4                   False                        False                 False   \n",
       "\n",
       "   category_code_software  category_code_sports  category_code_transportation  \\\n",
       "0                   False                 False                         False   \n",
       "1                   False                 False                         False   \n",
       "2                   False                 False                         False   \n",
       "3                    True                 False                         False   \n",
       "4                   False                 False                         False   \n",
       "\n",
       "   category_code_travel  category_code_web  status_acquired  status_closed  \n",
       "0                 False              False             True          False  \n",
       "1                 False              False             True          False  \n",
       "2                 False               True             True          False  \n",
       "3                 False              False             True          False  \n",
       "4                 False              False            False           True  \n",
       "\n",
       "[5 rows x 1619 columns]"
      ]
     },
     "execution_count": 1763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nominal Data = named data (No Order):example = gender(m/f), age, groups Use One-Hot Encoding.\n",
    "Ordinal Data (Clear Order): example =  1,2,3, Education = High School, Middle Schoo, =  Use Label Encoding.\n",
    "\n",
    "In our analysis, the majority of the categorical data exhibited a nominal nature, Consequently, we opted for one-hot encoding to represent each category as a binary column. This method ensures the independence of categories, eliminating the risk of introducing unintended ordinal relationships. \n",
    "\n",
    "Update: I have a problem because when using One hot enconding it creates binary features, and it lead to a large number \n",
    "of new features, so i need to find another way to convert the categorical data to numerical.\n",
    "Update 2: #As I expected i was triying to us get_dummies(one-hot encoding ) but it creates 1619 columns way to long \n",
    "#create a new column for each unique value, so this is not an option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 .  Data Analysiss ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is cleaned, we will explore our data with descriptive and graphical statistics to describe and summarize our variables. In this stage, you will find yourself classifying features and determining their correlation with the target variable and each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now use 'encoded_data' in the correlation calculation\n",
    "# data_encoded = data_encoded\n",
    "# column_names = data_encoded.columns.tolist()\n",
    "# print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1765,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Now use 'encoded_data' in the correlation calculation\n",
    "# data_encoded = data_encoded\n",
    "# column_names = data_encoded.columns.tolist()\n",
    "\n",
    "# # Identify the column name representing 'status' after one-hot encoding\n",
    "# status_column_name = [col for col in column_names if 'status' in col.lower()][0]\n",
    "\n",
    "\n",
    "# # Extracting feature matrix\n",
    "# feature_matrix = your_data_df[column_names]\n",
    "\n",
    "# def calculate_correlations(df: pd.DataFrame, target: pd.Series) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Calculates the correlations of all columns with regards to the target and returns a DataFrame with all column names\n",
    "#     and their correlation coefficient with regards to the target.\n",
    "\n",
    "#     :param df: Pandas DataFrame\n",
    "#     :param target: Pandas Series with target values\n",
    "#     :return: Pandas DataFrame with column names and their correlation coefficient with regards to the target\n",
    "#     \"\"\"\n",
    "#     # Calculate correlations\n",
    "#     correlations = df.corrwith(target)\n",
    "    \n",
    "#     # Create a DataFrame with column names and correlation coefficients\n",
    "#     correlation_df = pd.DataFrame(correlations, columns=['correlation_coefficient'])\n",
    "    \n",
    "#     return correlation_df\n",
    "\n",
    "# # Now you can calculate correlations using the identified 'status' column name\n",
    "# xcorrelations = calculate_correlations(feature_matrix, encoded_data[status_column_name])\n",
    "\n",
    "# # Display the correlations\n",
    "# print(xcorrelations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforming status(target variable) from categorical to numerical values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Detect and address outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Remove or impute incorrect or inconsistent data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the inputs and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5- Data Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6- Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7- Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8-  Model Evaluation:\n",
    "#### Confusion Matrix and Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 - Print a classification report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
